import argparse

import torch
from huggingface_hub import HfApi
from transformers import AutoModelForCausalLM


class HFModel:
    def __init__(self, model_name):
        self.name = model_name
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print("Using device:", self.device)

    def __enter__(self):
        print(f"Loading Model {self.name}")
        with torch.no_grad():
            self.model = AutoModelForCausalLM.from_pretrained(self.name)
            self.model = self.model.to(self.device)
            self.model.eval()
            return self.model

    def __exit__(self, type, value, traceback):
        print(f"Unloading Model {self.name}")
        del self.model


def merge_n_models(model_names):
    with torch.no_grad():
        with HFModel(model_names[0]) as blended_model:

            # zero out blended models params
            for p in blended_model.parameters():
                p.data *= 0

            for mn in model_names:
                with HFModel(mn) as temp_model:
                    for p1, p2 in zip(blended_model.parameters(), temp_model.parameters()):
                        p1.data += p2.data * (1 / len(model_names))
                del temp_model
            return blended_model


def upload_expert(merged_model, args):
    sources = "\n".join(map(lambda mn: f"- [{mn}](https://huggingface.co/{mn})", args.experts))

    model_card_yaml = f"""---
tags:
- MDEL
---

# Model Name
{args.hf_repo}

# Model Description
This model was generated by averaging the weights of the following models
{sources}
"""
    print(model_card_yaml)

    print("Pushing Model to Hub")
    merged_model.push_to_hub(args.hf_repo, model_card=model_card_yaml)

    print("Pushing Model Card to Hub")

    # Upload model card
    with open("./README.md", "w") as f:
        f.write(model_card_yaml)
    api = HfApi()
    api.upload_file(
        path_or_fileobj="./README.md",
        path_in_repo="README.md",
        repo_id=args.hf_repo,
        repo_type="model",
    )


def parse_args():
    parser = argparse.ArgumentParser(description='Merge expert models and upload to the HuggingFace Hub')
    parser.add_argument('--hf-repo', type=str, required=True,
                        help='Name of the repo to upload the merged model e.g. MDEL/merged-arxiv-github')
    parser.add_argument('-e', '--expert', action='append',
                        help='Name of an expert repo e.g MDEL/expert-arxiv (use this flag multiple times)',
                        required=True, dest='experts')

    return parser.parse_args()


if __name__ == '__main__':
    args = parse_args()

    if (len(args.experts) < 2):
        print("Must specify at least 2 experts to merge")
        exit(1)

    merged_model = merge_n_models(args.experts)
    upload_expert(merged_model, args)
